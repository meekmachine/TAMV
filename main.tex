\documentclass[11pt]{article}

\usepackage{acl}

\usepackage{times}
\usepackage{latexsym}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{inconsolata}
\usepackage{graphicx}

\title{Dependency-Based TAMV Extraction with spaCy/UD for Interpretable Prediction of Register, Toxicity, and VAD}

\author{Jonathan Sutton Fields \\
  Florida International University \\
  11200 SW 8th Street, Miami, FL 33199 \\
  \texttt{jfiel029@fiu.edu} \\\And
  Dr. Samira Zad \\
  Florida International University \\
  11200 SW 8th Street, Miami, FL 33199 \\
  \texttt{szad@fiu.edu} \\}

\begin{document}
\maketitle

\begin{abstract}
\begin{itemize}
  \item We present a feature-extraction process for extracting tense--aspect--mood--voice (TAMV) from dependency-parsed texts and uses these features for interpretable prediction tasks in discourse analysis.
  \item We show that TAMV can be reliably inferred from dependency parses produced by the spaCy library for python. And, additionally, that Universal Dependencies (UD) representation is well-suited to robust large-scale extraction. \citep{Ramm2017AnnotatingGerman,Nivre2010DependencyParsing,Okhapkin2021ConstructingLibraries}
  \item We evaluate three prediction problems \textbf{separately}: register prediction, toxicity prediction, and VAD prediction, using task-appropriate datasets and metrics.
  \item We ground our hypothesis in Longman Grammar's documentation of register-conditioned TAMV variation, and derive validation test cases from its examples to evaluate extraction accuracy (Longman is not used as a prediction dataset). \citep{Biber20101999LongmanEnglish}
\end{itemize}
\end{abstract}

\section{Introduction}
\begin{itemize}
  \item \textbf{Motivation:} Verb phrase choices encode temporal framing (tense/aspect), stance (mood/modality), and agency (voice); these grammatical choices vary systematically by register and interactional context. \citep{Biber20101999LongmanEnglish}
  \item \textbf{Goal:} Build an interpretable TAMV extraction pipeline from dependency structure and test its usefulness in three downstream prediction settings \emph{evaluated independently}.
  \item \textbf{Claims:}
    \begin{itemize}
      \item (C1) TAMV can be extracted reliably from \textbf{spaCy} dependency parses under a UD-style representation. \citep{Ramm2017AnnotatingGerman,Nivre2010DependencyParsing}
      \item (C2) Extracted TAMV distributions can predict \textbf{register} on Brown. \citep{19684/682R15.00.}
      \item (C3) The same extracted representation supports \textbf{separate} prediction of toxicity and VAD when paired with task-appropriate supervision (dataset citations to be added once present in \texttt{custom.bib}). 
    \end{itemize}
  \item \textbf{Contributions:}
    \begin{itemize}
      \item spaCy-only Universal Dependency (UD) TAMV extraction with intrinsic evaluation. \citep{Ramm2017AnnotatingGerman,DonickeClause-LevelGerman}
      \item Register prediction on Brown using extracted TAMV distributions. \citep{19684/682R15.00.}
      \item Task-separable experimental design: distinct models/labels/metrics for register vs toxicity vs VAD.
      \item Intrinsic validation using test cases derived from Longman Grammar examples. \citep{Biber20101999LongmanEnglish}
    \end{itemize}
\end{itemize}

\section{Background}
\subsection{Register and grammatical variation}
\begin{itemize}
  % TODO: First explain about what register actually is and the different varieties of spoken and written English
  \item \textbf{What is register?} Register refers to systematic linguistic variation conditioned by situational context---including mode (spoken vs.\ written), interactivity, production circumstances, and communicative purpose. \citep{Biber20101999LongmanEnglish}
  \item \textbf{Major varieties:} Longman Grammar distinguishes four core registers: \emph{conversation} (informal, interactive, real-time), \emph{fiction} (narrative, edited, monologic), \emph{news} (informational, edited, public), and \emph{academic} (expository, highly edited, specialized). \citep{Biber20101999LongmanEnglish}
  \item Register differences correspond to systematic frequency shifts in grammatical constructions; verb phrase systems are a major axis of variation. \citep{Biber20101999LongmanEnglish}
  % TODO: lets find more findings from Longman Grammar to substantiate each category.
  \item \textbf{Tense/Aspect:} Present tense dominates conversation; past tense dominates fiction and news. Perfect aspect is most frequent in news and academic writing. \citep{Biber20101999LongmanEnglish}
    \begin{itemize}
      \item Conversation: \emph{``I think he knows what he's doing.''}
      \item Fiction: \emph{``She walked into the room and saw him standing there.''}
      \item News: \emph{``The committee has voted to approve the measure.''}
    \end{itemize}
  \item \textbf{Mood/Modality:} Modal verbs are frequent in conversation (expressing stance, politeness, hedging); academic prose favors epistemic modals (\emph{may}, \emph{might}, \emph{could}) for hedged claims. \citep{Biber20101999LongmanEnglish}
    \begin{itemize}
      \item Conversation: \emph{``You should try this---it might be good.''}
      \item Academic: \emph{``These results may indicate a relationship between the variables.''}
    \end{itemize}
  \item \textbf{Voice:} Passive voice is rare in conversation but common in academic and news registers, where agent de-emphasis and information packaging motivate its use. \citep{Biber20101999LongmanEnglish}
    \begin{itemize}
      \item Conversation: \emph{``They fired him last week.''} (active preferred)
      \item Academic: \emph{``The samples were analyzed using spectroscopy.''} (passive preferred)
      \item News: \emph{``Three people were killed in the accident.''} (passive preferred)
    \end{itemize}
\end{itemize}

\subsection{Dependency parsing and UD vs.\ SD framing}
\begin{itemize}
  \item Dependency parsing provides relations required to detect verbal complexes, auxiliaries, passives, and clause structure. \citep{Nivre2010DependencyParsing}
  \item \textbf{Theoretical foundations:} These two parsing conventions reflect different grammatical traditions:
    \begin{itemize}
      \item \textbf{SD} derives from Chomskyan phrase structure grammar (Government \& Binding Theory), where the finite element carrying tense/agreement features governs the clause.
      \item \textbf{UD} derives from Tesni\`{e}re's Dependency Grammar (1959)---predating Chomsky---which argues the lexical/content word should be the syntactic head, with function words as dependents.
    \end{itemize}
  \item \textbf{SD (Stanford Dependencies):} Convention where the finite auxiliary is the syntactic head of the clause (e.g., \emph{has} heads \emph{has eaten}). Used by Mate parser and TMV-annotator. \citep{Ramm2017AnnotatingGerman}
  \item \textbf{UD (Universal Dependencies):} Convention where the \emph{content verb} is the head and auxiliaries attach as dependents (e.g., \emph{eaten} heads \emph{has eaten}). Used by spaCy and most current NLP pipelines. \citep{Nivre2010DependencyParsing}
  \item We frame extraction in a \textbf{UD-style} representation (as used by modern pipelines) and argue it is a more current, standardized basis for scalable extraction than older SD-style conventions. \citep{Nivre2010DependencyParsing,Okhapkin2021ConstructingLibraries}
\end{itemize}

\subsection{Temporal structure and tense/aspect modeling assumptions}
\begin{itemize}
  \item Temporal structure annotation provides a foundation for disambiguating tense/aspect distinctions and clarifying ambiguous cases. \citep{Derczynski2012AnStructure}
\end{itemize}

\section{Related Work}
\subsection{Linguistic evidence for TAMV and register}
\begin{itemize}
  \item Longman Grammar documents register-conditioned differences in verb phrase systems that motivate TAMV as a register-sensitive feature family. \citep{Biber20101999LongmanEnglish}
\end{itemize}

\subsection{Dependency-based TAMV/TMV extraction}
\begin{itemize}
  \item \textbf{Ramm et al.\ (2017):} The TMV-annotator extracts tense, mood, and voice from verbal complexes using rule-based patterns over dependency parses. Their system uses the \textbf{Mate parser}, which follows the older Stanford Dependencies (SD) convention where auxiliaries head verbal complexes. \citep{Ramm2017AnnotatingGerman}
  \item \textbf{spaCy:} A widely-used open-source NLP library that provides fast, accurate dependency parsing using neural models trained on Universal Dependencies (UD) treebanks. Unlike Mate, spaCy treats the \emph{content verb} as the head, with auxiliaries as dependents. \citep{Okhapkin2021ConstructingLibraries}
  \item \textbf{Mate vs.\ spaCy:} Mate parser (SD-style) is accurate but requires Java and pre-trained models that are less actively maintained. spaCy (UD-style) is Python-native, faster, and better supported for modern NLP pipelines. Our work adapts Ramm et al.'s extraction logic to spaCy's UD representation.
  \item Clause-level TMV/modality tagging for German motivates clause segmentation choices and highlights extraction difficulty cases. \citep{DonickeClause-LevelGerman}
\end{itemize}

\subsection{Benchmarks for downstream prediction}
\begin{itemize}
  \item Brown provides a classic genre/register-labeled corpus suitable for testing whether extracted TAMV distributions predict register. \citep{19684/682R15.00.}
  \item (To add) Toxicity and VAD benchmarks: insert once their BibTeX entries are in \texttt{custom.bib}.
\end{itemize}

\section{Data}
\begin{itemize}
  \item \textbf{Register prediction:} Brown corpus (genre/register labels). \citep{19684/682R15.00.}
  \item \textbf{TAMV intrinsic evaluation:} Test cases derived from Longman Grammar examples, providing gold TAMV annotations for verbal complexes. \citep{Biber20101999LongmanEnglish,Ramm2017AnnotatingGerman}
  \item \textbf{Toxicity prediction:} (To add) dataset used in the slides once its BibTeX key is available.
  \item \textbf{VAD prediction:} (To add) dataset/label source once its BibTeX key is available.
\end{itemize}

\section{Methods}
\subsection{spaCy-only dependency parsing and preprocessing}
\begin{itemize}
  \item Parse with spaCy and extract POS/dependencies/lemmas/morph features needed for TAMV rules. \citep{Nivre2010DependencyParsing,Okhapkin2021ConstructingLibraries}
  \item Implement UD-aligned rule patterns for verbal-complex identification and clause segmentation. \citep{Ramm2017AnnotatingGerman,DonickeClause-LevelGerman}
\end{itemize}

\subsection{TAMV extraction}
\begin{itemize}
  \item \textbf{Tense:} Determined by auxiliary presence and verb morphology---\emph{will/shall} signal future; \emph{-ed} or irregular past forms signal past; base/\emph{-s} forms signal present. \citep{Biber20101999LongmanEnglish}
  \item \textbf{Aspect:} Progressive detected via \emph{be} + \emph{-ing}; perfect detected via \emph{have} + past participle; combinations yield perfect-progressive. \citep{Biber20101999LongmanEnglish}
  \item \textbf{Mood/Modality:} Modal verbs (\emph{can}, \emph{could}, \emph{may}, \emph{might}, \emph{must}, \emph{shall}, \emph{should}, \emph{will}, \emph{would}) detected by POS tag and lemma; imperative detected by base form without subject; subjunctive detected in \emph{that}-clause complements of mandate verbs. \citep{Biber20101999LongmanEnglish}
  \item \textbf{Voice:} Passive detected via \emph{be} + past participle where the subject is the logical patient (dependency role \texttt{nsubjpass} or \texttt{nsubj:pass}). \citep{Ramm2017AnnotatingGerman}
  \item Rule inventory grounded in prior TMV/TAMV dependency tagging work. \citep{Ramm2017AnnotatingGerman,DonickeClause-LevelGerman}
\end{itemize}

\subsection{Task-specific feature sets (kept separate)}
\begin{itemize}
  \item \textbf{Register task features:} TAMV distributions (counts/normalized rates) over documents/segments.
  \item \textbf{Toxicity task features:} TAMV distributions and/or TAMV trajectories over turns (if conversational); evaluated only on toxicity labels.
  \item \textbf{VAD task features:} TAMV + lexical features used to predict continuous VAD labels (or binned labels), evaluated only on VAD supervision.
\end{itemize}

\section{Experiments}
\subsection{Intrinsic evaluation: TAMV extraction reliability}
\begin{itemize}
  \item Evaluate extracted TAMV against gold annotations derived from Longman Grammar examples: per-dimension accuracy/F1 and joint-label accuracy; error taxonomy. \citep{Biber20101999LongmanEnglish,Ramm2017AnnotatingGerman}
\end{itemize}

\subsection{Register prediction (Brown)}
\begin{itemize}
  \item Predict Brown genre/register from TAMV distributions; report accuracy/F1 and confusion patterns. \citep{19684/682R15.00.}
  \item Compare learned TAMV-by-register trends to patterns documented in Longman Grammar as a sanity check. \citep{Biber20101999LongmanEnglish}
\end{itemize}

\subsection{Toxicity prediction (separate)}
\begin{itemize}
  \item Train a toxicity classifier using TAMV-based features; report AUC/F1 (dataset citations to be added).
  \item If conversational: include trajectory features (early vs late windows), but evaluate only against toxicity labels.
\end{itemize}

\subsection{VAD prediction (separate)}
\begin{itemize}
  \item Predict VAD labels (continuous regression or binned classification), evaluated only against VAD supervision (dataset/lexicon citations to be added).
  \item Report correlation/RMSE (regression) or accuracy/F1 (classification), depending on labeling scheme.
\end{itemize}

\section{Results}
\begin{itemize}
  \item \textbf{TAMV reliability:} performance on Longman-derived test cases and major error sources. \citep{Biber20101999LongmanEnglish,Ramm2017AnnotatingGerman}
  \item \textbf{Register:} Brown prediction performance + interpretable TAMV feature importance; sanity-check alignment with Longman. \citep{19684/682R15.00.,Biber20101999LongmanEnglish}
  \item \textbf{Toxicity:} toxicity prediction results (add citations once bib keys exist).
  \item \textbf{VAD:} VAD prediction results (add citations once bib keys exist).
\end{itemize}

\section{Analysis}
\begin{itemize}
  \item Interpretability: which TAMV dimensions drive register prediction vs toxicity vs VAD (analyzed separately).
  \item Error analysis: how dependency parsing/clause segmentation affects each TAMV dimension; connect to temporal structure assumptions. \citep{Derczynski2012AnStructure,Nivre2010DependencyParsing}
\end{itemize}

\section{Discussion}
\begin{itemize}
  \item Strengths: interpretable grammatical signal; portable extraction via spaCy/UD-style dependency structure. \citep{Nivre2010DependencyParsing,Okhapkin2021ConstructingLibraries}
  \item What differs across tasks: why TAMV helps register, and what additional signals may be needed for toxicity and VAD (without conflating the evaluations).
  \item Role of Longman Grammar: theoretical grounding for TAMV--register connection and source of validation test cases, not a prediction dataset. \citep{Biber20101999LongmanEnglish}
\end{itemize}

\section{Conclusion}
\begin{itemize}
  \item We present a spaCy-only UD-style TAMV extraction pipeline with intrinsic validation and show that extracted TAMV distributions predict register on Brown.
  \item We evaluate toxicity and VAD as separate supervised tasks using the same extraction backbone (final citations added once their BibTeX entries are included).
\end{itemize}

\section*{Limitations}
\begin{itemize}
  \item Dependency parsing and clause segmentation errors can propagate into TAMV labeling. \citep{Nivre2010DependencyParsing}
  \item TAMV scope limitations (modal ambiguity, passive/participle ambiguity, non-finite handling) remain open. \citep{Ramm2017AnnotatingGerman,DonickeClause-LevelGerman}
  \item Toxicity/VAD sections require adding the dataset and lexicon BibTeX entries currently missing from the pasted snippet.
\end{itemize}

\section*{Acknowledgments}
\begin{itemize}
  \item (To fill) Lab, advisor(s), funding, dataset/tool authors, and reviewers.
\end{itemize}

\bibliography{references}

\end{document}